{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am fine\n"
     ]
    }
   ],
   "source": [
    "print(\"I am fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/llama2-py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/root/anaconda3/envs/llama2-py311/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"/120040051/hf_llama2\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"/120040051/hf_llama2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(sentences, tokenizer, model, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    perplexities = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the input sentence\n",
    "        encodings = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "        # Move encodings to the same device as the model\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        attention_mask = encodings.attention_mask.to(device)\n",
    "\n",
    "        # Calculate Negative Log-Likelihood\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids, attention_mask=attention_mask)\n",
    "            neg_log_likelihood = outputs.loss * input_ids.size(1)  # Multiply by sequence length\n",
    "\n",
    "        # Calculate Perplexity and append to list\n",
    "        ppl = torch.exp(neg_log_likelihood / input_ids.size(1))  # Divide by sequence length\n",
    "        perplexities.append(ppl.item())\n",
    "\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.415712356567383, 20.11915397644043, 151.33119201660156]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"A man is eating pizza in the restaurant.\", \"A man is drinking beer in the restaurant.\", \"A man is play golf in the restaurant.\"]\n",
    "perplexity_values = calculate_perplexity(sentences, tokenizer, model, device)\n",
    "print(perplexity_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
